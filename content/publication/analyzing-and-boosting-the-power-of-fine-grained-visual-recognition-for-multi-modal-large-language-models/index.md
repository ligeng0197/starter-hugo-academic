---
title: Analyzing and Boosting the Power of Fine-Grained Visual Recognition for
  Multi-modal Large Language Models
publication_types:
  - "1"
authors:
  - Hulingxiao He
  - Geng Li
  - Zijun Geng
  - Jinglin Xu
  - Yuxin Peng
publication: ""
publication_short: ICLR 2025
abstract: Multi-modal large language models (MLLMs) have shown remarkable
  abilities in various visual understanding tasks. However, MLLMs still struggle
  with fine-grained visual recognition (FGVR), which aims to identify
  subordinate-level categories from images. This can negatively impact more
  advanced capabilities of MLLMs, such as object-centric visual question
  answering and reasoning. In our study, we revisit three quintessential
  capabilities of MLLMs for FGVR, including object information extraction,
  category knowledge reserve, object-category alignment, and position of the
  root cause as a misalignment problem. To address this issue, we present
  Finedefics, an MLLM that enhances the model's FGVR capability by incorporating
  informative attribute descriptions of objects into the training phase. We
  employ contrastive learning on object-attribute pairs and attribute-category
  pairs simultaneously and use examples from similar but incorrect categories as
  hard negatives, naturally bringing representations of visual objects and
  category names closer. Extensive evaluations across multiple popular FGVR
  datasets demonstrate that Finedefics outperforms existing MLLMs of comparable
  parameter sizes, showcasing its remarkable efficacy.
draft: false
featured: false
image:
  filename: iclr.jpg
  focal_point: Smart
  preview_only: false
date: 2025-05-12T06:05:23.631Z
---
