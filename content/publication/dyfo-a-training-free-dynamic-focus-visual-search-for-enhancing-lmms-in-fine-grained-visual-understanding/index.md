---
title: "DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in
  Fine-Grained Visual Understanding"
publication_types:
  - "1"
authors:
  - Geng Li
  - Jinglin Xu
  - Yunzhen Zhao
  - Yuxin Peng
doi: https://doi.org/10.48550/arXiv.2504.14920
publication: Accepted by CVPR 2025 Hightlight
publication_short: CVPR 2025 Hightlight
abstract: Humans can effortlessly locate desired objects in cluttered
  environments, relying on a cognitive mechanism known as visual search to
  efficiently filter out irrelevant information and focus on task-related
  regions. Inspired by this process, we propose Dyfo (Dynamic Focus), a
  training-free dynamic focusing visual search method that enhances fine-grained
  visual understanding in large multimodal models (LMMs). Unlike existing
  approaches which require additional modules or data collection, Dyfo leverages
  a bidirectional interaction between LMMs and visual experts, using a Monte
  Carlo Tree Search (MCTS) algorithm to simulate human-like focus adjustments.
  This enables LMMs to focus on key visual regions while filtering out
  irrelevant content, without introducing additional training caused by
  vocabulary expansion or the integration of specialized localization modules.
  Experimental results demonstrate that Dyfo significantly improves fine-grained
  visual understanding and reduces hallucination issues in LMMs, achieving
  superior performance across both fixed and dynamic resolution models.
draft: false
featured: true
image:
  filename: method.svg
  focal_point: Smart
  preview_only: false
summary: We propose Dyfo, a training-free visual search method that dynamically
  guides large multimodal models to focus on task-relevant regions using
  MCTS-based interaction with visual experts, significantly enhancing
  fine-grained understanding and reducing hallucinations without additional
  training or modules.
date: 2025-04-12T05:54:00.000Z
---
